{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, './python_src/')\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import load_proteins as load\n",
    "import protein_algs as palgs\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from pymol import cmd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks\n",
    "- Try running full analysis for GCK and see if result spreadsheat is the same\n",
    "- pfkA resturns error in topo strain pathway analysis\n",
    "- put more code into python library\n",
    "    - maybe one centralized python source file that then loads multiple other files\n",
    "    - load protein dictionary object\n",
    "    - analyze topology - maybe return full skeletons\n",
    "    - analyze skeletons - return pathways and hinges\n",
    "    - display routines\n",
    "- return all proteins and check results\n",
    "- check proteins in check special function\n",
    "- create environment configuration file\n",
    "- check citations for list of proteins\n",
    "- do not use pure proximal contacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = pd.read_excel('data/proteins.xlsx', sheet_name='allosteric')\n",
    "\n",
    "df_db.fillna(\"\", inplace=True)\n",
    "\n",
    "df_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_bond_types=[('proximal', '')]\n",
    "\n",
    "\n",
    "selection = np.arange(16, 30)\n",
    "\n",
    "for index, row in df_db.iterrows():\n",
    "    \n",
    "    if row['skip'] == 'yes':\n",
    "        continue\n",
    "\n",
    "    if index not in selection:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    prot_id = row['protein_id']\n",
    "    \n",
    "    print(index, prot_id)\n",
    "    \n",
    "    display(row)\n",
    "\n",
    "    \n",
    "    iPDB_id = row['inactive_PDB']\n",
    "    ichain_list = row['inactive_chains']\n",
    "    load.preprocess(prot_id, iPDB_id, check=True)\n",
    "    \n",
    "    aPDB_id = row['active_PDB']\n",
    "    achain_list = row['active_chains']\n",
    "    load.preprocess(prot_id, aPDB_id, check=True)\n",
    "\n",
    "    reg_list = row['regulatory_ids']\n",
    "    sub_list = row['substrate_ids']\n",
    "    \n",
    "    print(reg_list, sub_list)\n",
    "    \n",
    "    idf_prot, idf_bonds = load.load_protein(prot_id, iPDB_id, ichain_list, reg_list, sub_list, exclude_bond_types=exclude_bond_types)\n",
    "    adf_prot, adf_bonds = load.load_protein(prot_id, aPDB_id, achain_list, reg_list, sub_list, exclude_bond_types=exclude_bond_types)\n",
    "\n",
    "    display(idf_prot)\n",
    "    display(adf_prot)\n",
    "    \n",
    "\n",
    "    # if activated then choose active configuration as reference\n",
    "    # this makes the topological features prettier\n",
    "    if row['mechanism'] == 'activated':\n",
    "        df_prot_ref = adf_prot\n",
    "        df_bonds_ref = adf_bonds\n",
    "        df_prot_def = idf_prot\n",
    "        df_bonds_def = idf_bonds\n",
    "    else:\n",
    "        df_prot_ref = idf_prot\n",
    "        df_bonds_ref = idf_bonds\n",
    "        df_prot_def = adf_prot\n",
    "        df_bonds_def = adf_bonds\n",
    "        \n",
    "    \n",
    "    df_prot_merged = palgs.merge_structures(df_prot_ref, df_prot_def)\n",
    "    df_bonds_ref_merged = palgs.merge_bonds(df_prot_ref, df_bonds_ref, df_prot_merged)\n",
    "    \n",
    "    \n",
    "    print(\"Merged Protein Structure:\")\n",
    "    display(df_prot_merged)\n",
    "    \n",
    "    print(\"Merged Reference Bonds:\")\n",
    "    display(df_bonds_ref_merged)\n",
    "    \n",
    "    palgs.df_to_pdb(prot_id, df_prot_ref, label='full_reference')\n",
    "    palgs.df_to_pdb(prot_id, df_prot_def, label='full_deformed')\n",
    "    \n",
    "    palgs.df_to_pdb(prot_id, df_prot_merged, suffix='_ref', label='merged_reference')\n",
    "    palgs.df_to_pdb(prot_id, df_prot_merged, suffix='_def', label='merged_deformed')\n",
    "    \n",
    "     \n",
    "    with open(\"data/\" + prot_id + \"/structure.pkl\", 'wb') as pkl_file:\n",
    "        data = {'reference structure': df_prot_ref, 'reference bonds': df_bonds_ref,\n",
    "               'deformed structure': df_prot_def, 'deformed bonds': df_bonds_def,\n",
    "               'merged structure': df_prot_merged, 'merged reference bonds': df_bonds_ref_merged}\n",
    "        pickle.dump(data, pkl_file)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection = np.arange(51)\n",
    "\n",
    "for index, row in df_db.iterrows():\n",
    "        \n",
    "    if row['skip'] == 'yes':\n",
    "        continue\n",
    "\n",
    "    if index not in selection:\n",
    "        continue\n",
    "        \n",
    "    print(row['protein_id'])\n",
    "\n",
    "    cmd.reinitialize()\n",
    "    cmd.run(\"python_src/pymol_cmds.py\")\n",
    "    cmd.do(\"show_disp {}\".format(index))\n",
    "    cmd.ray(800, 800)\n",
    "    cmd.png(\"data/figs/test_disp.png\")\n",
    "\n",
    "    \n",
    "    fig, ax1 = plt.subplots(1, 1, constrained_layout=True, figsize=(6, 6))\n",
    "    \n",
    "    ax1.imshow(mpimg.imread('data/figs/test_disp.png'))\n",
    "    \n",
    "    ax1.get_xaxis().set_ticks([])\n",
    "    ax1.get_yaxis().set_ticks([])\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# selection = [53]\n",
    "\n",
    "if os.path.exists(\"data/results.xlsx\"):\n",
    "    df_results =  pd.read_excel('data/results.xlsx')\n",
    "\n",
    "else:\n",
    "    df_results = pd.DataFrame(columns=[\"protein_id\", \"subunit_structure\", \"lrmsd_norm\", \n",
    "                                       \"hinge_scale\", \"overlap\", \"sector_sizes\", \n",
    "                                       \"multi_hinge_scale\", \"multi_overlap\", \"multi_sector_sizes\",\n",
    "                                      \"allo_path_scale\", \"allo_path_norm\", \n",
    "                                       \"coop_path_scale\", \"coop_path_norm\"])\n",
    "\n",
    "df_results.set_index(\"protein_id\", inplace=True)\n",
    "\n",
    "df_results['sector_sizes'] = df_results['sector_sizes'].astype('object')\n",
    "df_results['multi_sector_sizes'] = df_results['multi_sector_sizes'].astype('object')\n",
    "\n",
    "display(df_results)\n",
    "    \n",
    "l0 = 15\n",
    "\n",
    "for index, row in df_db.iterrows():\n",
    "    \n",
    "    if row['skip'] == 'yes':\n",
    "        continue\n",
    "\n",
    "    if index not in selection:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    N_sectors = df_db.loc[index, 'n_sectors']\n",
    "    \n",
    "    \n",
    "#     if N_sectors == 2:\n",
    "#         continue\n",
    "    \n",
    "    prot_id = row['protein_id']\n",
    "    \n",
    "    print(\"######################################################\")\n",
    "        \n",
    "    print(index, prot_id)\n",
    "    \n",
    "#     df_results.drop(index=prot_id, inplace=True, errors='ignore')\n",
    "    \n",
    "    df_results.loc[prot_id, 'subunit_structure'] = row['subunit_structure']\n",
    "    \n",
    "    with open(\"data/\" + prot_id + \"/structure.pkl\", 'rb') as pkl_file:\n",
    "        data = pickle.load(pkl_file)\n",
    "        df_prot_merged = data['merged structure']\n",
    "        df_bonds_ref_merged = data['merged reference bonds']\n",
    "        \n",
    "        df_prot_ref = data['reference structure']\n",
    "        df_bonds_ref = data['reference bonds']\n",
    "        \n",
    "    print(\"Protein Size:\", len(df_prot_merged.index), flush=True)\n",
    "    \n",
    "    # calculate local deformation\n",
    "    palgs.calc_local_rmsd(df_prot_merged, l0=l0)\n",
    "      \n",
    "    \n",
    "#     edgei, edgej = palgs.find_edges(df_prot_ref, df_bonds_ref)\n",
    "        \n",
    "        \n",
    "    has_allo_path = False\n",
    "    has_coop_path = False\n",
    "    # find allosteric pathways\n",
    "    if len(df_prot_merged.query(\"allo_site!=-1 and active_site==-1\")) > 0 and len(df_prot_merged.query(\"allo_site==-1 and active_site!=-1\")) > 0:\n",
    "        has_allo_path = True\n",
    "    \n",
    "        allo_strain_path_scales, allo_strain_path_lengths, allo_strain_paths, max_edge_scale = palgs.find_allo_strain_path(df_prot_merged, df_bonds_ref_merged)\n",
    "        allo_strain_path_scale = allo_strain_path_scales[0]\n",
    "        allo_strain_path = allo_strain_paths[0]\n",
    "                \n",
    "        print(\"Allo Path Scale:\", allo_strain_path_scale)\n",
    "        \n",
    "        df_results.loc[prot_id, 'allo_path_scale'] = allo_strain_path_scale\n",
    "           \n",
    "        allo_path_norm = df_prot_merged.iloc[allo_strain_path[0]]['lrmsd']\n",
    "        \n",
    "        df_results.loc[prot_id, 'allo_path_norm'] = allo_path_norm\n",
    "        \n",
    "        print(\"Allo Path Norm:\", allo_path_norm)\n",
    "            \n",
    "        df_prot_merged['allo_path'] = -1\n",
    "        for i, vi in enumerate(allo_strain_path):\n",
    "            df_prot_merged.iloc[vi, df_prot_merged.columns.get_loc(\"allo_path\")] = i\n",
    "            \n",
    "        df_bonds_ref_merged['allo_path_max_scale'] = max_edge_scale\n",
    "            \n",
    "\n",
    "    # find cooperative pathways\n",
    "    if len(df_prot_merged.query(\"allo_site==-1 and active_site!=-1\")['active_site'].unique()) > 1:\n",
    "        has_coop_path = True\n",
    "        \n",
    "        coop_strain_path_scales, coop_strain_path_lengths, coop_strain_paths, max_edge_scale = palgs.find_coop_strain_path(df_prot_merged, df_bonds_ref_merged)\n",
    "        coop_strain_path_scale = coop_strain_path_scales[0]\n",
    "        coop_strain_path = coop_strain_paths[0]\n",
    "        \n",
    "        print(\"Coop Path Scale:\", coop_strain_path_scale)\n",
    "    \n",
    "        df_results.loc[prot_id, 'coop_path_scale'] = coop_strain_path_scale\n",
    "        \n",
    "        coop_path_norm = np.max([df_prot_merged.iloc[coop_strain_path[0]]['lrmsd'], df_prot_merged.iloc[coop_strain_path[-1]]['lrmsd']])\n",
    "        \n",
    "        df_results.loc[prot_id, 'coop_path_norm'] = coop_path_norm\n",
    "        \n",
    "        print(\"Coop Path Norm:\", coop_path_norm)\n",
    "            \n",
    "        \n",
    "        df_prot_merged['coop_path'] = -1\n",
    "        for i, vi in enumerate(coop_strain_path):\n",
    "            df_prot_merged.iloc[vi, df_prot_merged.columns.get_loc(\"coop_path\")] = i\n",
    "            \n",
    "        df_bonds_ref_merged['coop_path_max_scale'] = max_edge_scale\n",
    "    \n",
    "    if len(df_prot_merged.query(\"allo_site!=-1\")) > 0:\n",
    "        S_max = df_prot_merged.query(\"allo_site!=-1\")['lrmsd'].max()\n",
    "        print(\"S_max:\", S_max)\n",
    "        df_results.loc[prot_id, 'S_max'] = S_max\n",
    "\n",
    "        S_avg = df_prot_merged.query(\"allo_site!=-1\")['lrmsd'].mean()\n",
    "        print(\"S_avg:\", S_avg)\n",
    "        df_results.loc[prot_id, 'S_avg'] = S_avg\n",
    "        \n",
    "    if len(df_prot_merged.query(\"active_site!=-1\")) > 0:\n",
    "        T_max = df_prot_merged.query(\"active_site!=-1\")['lrmsd'].max()\n",
    "        print(\"T_max:\", T_max)\n",
    "        df_results.loc[prot_id, 'T_max'] = T_max\n",
    "        \n",
    "        T_avg = df_prot_merged.query(\"active_site!=-1\")['lrmsd'].mean()\n",
    "        print(\"T_avg:\", T_avg)\n",
    "        df_results.loc[prot_id, 'T_avg'] = T_avg\n",
    "        \n",
    "\n",
    "    if has_allo_path:\n",
    "        print(\"Using allosteric pathway normalization.\")\n",
    "        df_results.loc[prot_id, 'lrmsd_norm'] = df_results.loc[prot_id, 'allo_path_norm']\n",
    "    elif has_coop_path:\n",
    "        print(\"Using cooperative pathway normalization.\")\n",
    "        df_results.loc[prot_id, 'lrmsd_norm'] = df_results.loc[prot_id, 'coop_path_norm'] \n",
    "    # only has allosteric sites labeled\n",
    "    elif len(df_prot_merged.query(\"allo_site!=-1\")) > 0:\n",
    "        print(\"Using allosteric site normalization.\")\n",
    "        df_results.loc[prot_id, 'lrmsd_norm'] = df_results.loc[prot_id, 'S_avg']\n",
    "    # only has active sites labeled\n",
    "    elif len(df_prot_merged.query(\"active_site!=-1\")) > 0:\n",
    "        print(\"Using active site normalization.\")\n",
    "        df_results.loc[prot_id, 'lrmsd_norm'] = df_results.loc[prot_id, 'T_avg']\n",
    "    else:\n",
    "        print(\"Error finding normalization...\")\n",
    "        \n",
    "    print(\"Normalization:\", df_results.loc[prot_id, 'lrmsd_norm'])\n",
    "    \n",
    "    min_size = 200\n",
    "    \n",
    "    print(\"Min Sector Size:\", min_size)\n",
    "        \n",
    "    hinge_scale, hinge_overlap, sectors_to_verts = palgs.find_hinge(df_prot_merged, df_bonds_ref_merged, N_sectors=2, min_size=min_size)\n",
    "    \n",
    "    print(\"Hinge Scale:\", hinge_scale)\n",
    "    print(\"Overlap:\", hinge_overlap)\n",
    "    \n",
    "    \n",
    "    sector_sizes = [len(sectors_to_verts[si]) for si in range(len(sectors_to_verts))]\n",
    "    \n",
    "        \n",
    "    df_results.loc[prot_id, 'hinge_scale'] = hinge_scale\n",
    "    df_results.loc[prot_id, 'overlap'] = hinge_overlap\n",
    "    df_results.at[prot_id, 'sector_sizes'] = sector_sizes\n",
    "    \n",
    "    df_prot_merged['sector'] = -1\n",
    "    for si in range(len(sectors_to_verts)):\n",
    "        df_prot_merged.iloc[list(sectors_to_verts[si]), df_prot_merged.columns.get_loc(\"sector\")] = si\n",
    "    \n",
    "        \n",
    "    if N_sectors > 2:\n",
    "        \n",
    "        multi_hinge_scale, multi_hinge_overlap, sectors_to_verts = palgs.find_hinge(df_prot_merged, df_bonds_ref_merged, N_sectors=N_sectors, min_size=min_size)\n",
    "\n",
    "        sector_sizes = [len(sectors_to_verts[si]) for si in range(len(sectors_to_verts))]\n",
    "        \n",
    "        print(\"Multi Hinge Scale:\", multi_hinge_scale)\n",
    "        print(\"Multi Overlap:\", multi_hinge_overlap)\n",
    "\n",
    "        df_results.loc[prot_id, 'multi_hinge_scale'] = multi_hinge_scale\n",
    "        df_results.loc[prot_id, 'multi_overlap'] = multi_hinge_overlap\n",
    "        df_results.at[prot_id, 'multi_sector_sizes'] = sector_sizes\n",
    "        \n",
    "        df_prot_merged['multi_sector'] = -1\n",
    "        for si in range(len(sectors_to_verts)):\n",
    "            df_prot_merged.iloc[list(sectors_to_verts[si]), df_prot_merged.columns.get_loc(\"multi_sector\")] = si\n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    with open(\"data/\" + prot_id + \"/structure.pkl\", 'wb') as pkl_file:\n",
    "        data['merged structure'] = df_prot_merged\n",
    "        data['merged reference bonds'] = df_bonds_ref_merged\n",
    "        pickle.dump(data, pkl_file)\n",
    "        \n",
    "    print(\"######################################################\")\n",
    "        \n",
    "    print(\"Normalized Hinge Scale:\", hinge_scale/df_results.loc[prot_id, 'lrmsd_norm'])\n",
    "    print(\"Hinge Overlap:\", hinge_overlap)\n",
    "    \n",
    "    if N_sectors > 2:\n",
    "        print(\"Normalized Multidomain Hinge Scale:\", multi_hinge_scale/df_results.loc[prot_id, 'lrmsd_norm'])\n",
    "        print(\"Multidomain Hinge Overlap:\", multi_hinge_overlap)\n",
    "    \n",
    "    if has_allo_path:\n",
    "        print(\"Normalized Allo Pathway Scale:\", allo_strain_path_scale/df_results.loc[prot_id, 'lrmsd_norm'])\n",
    "    if has_coop_path:\n",
    "        print(\"Normalized Coop Pathway Scale:\", coop_strain_path_scale/df_results.loc[prot_id, 'lrmsd_norm'])\n",
    "        \n",
    "    print(\"######################################################\")\n",
    "        \n",
    "    display(df_results.loc[prot_id])\n",
    "        \n",
    "    df_results.to_excel(\"data/results.xlsx\") \n",
    "        \n",
    "display(df_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# selection = [53]\n",
    "\n",
    "for index, row in df_db.iterrows():\n",
    "        \n",
    "    if row['skip'] == 'yes':\n",
    "        continue\n",
    "\n",
    "    if index not in selection:\n",
    "        continue\n",
    "        \n",
    "    print(index, row['protein_id'])\n",
    "    \n",
    "#     print(df_results.loc[row['protein_id']])\n",
    "\n",
    "    cmd.reinitialize()\n",
    "    cmd.run(\"python_src/pymol_cmds.py\")\n",
    "    cmd.do(\"show_disp {}\".format(index))\n",
    "    cmd.ray(800, 800)\n",
    "    cmd.png('data/figs/{}_disp.png'.format(row['protein_id']))\n",
    "\n",
    "    cmd.reinitialize()\n",
    "    cmd.run(\"python_src/pymol_cmds.py\")\n",
    "    cmd.do(\"show_topo {}\".format(index))\n",
    "    cmd.ray(800, 800)\n",
    "    cmd.png('data/figs/{}_topo.png'.format(row['protein_id']))\n",
    "    \n",
    "    # cmd.reinitialize()\n",
    "    # cmd.run(\"python_src/pymol_cmds.py\")\n",
    "    # cmd.do(\"show_paths {}\".format(index))\n",
    "    # cmd.ray(800, 800)\n",
    "    # cmd.png('data/figs/{}_topo.png'.format(row['protein_id']))\n",
    "    \n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12, 6))\n",
    "    \n",
    "    ax1.imshow(mpimg.imread('data/figs/{}_disp.png'.format(row['protein_id'])))\n",
    "    \n",
    "    ax1.get_xaxis().set_ticks([])\n",
    "    ax1.get_yaxis().set_ticks([])\n",
    "    \n",
    "    ax2.imshow(mpimg.imread('data/figs/{}_topo.png'.format(row['protein_id'])))\n",
    "    \n",
    "    ax2.get_xaxis().set_ticks([])\n",
    "    ax2.get_yaxis().set_ticks([])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allo_topo]",
   "language": "python",
   "name": "conda-env-allo_topo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
